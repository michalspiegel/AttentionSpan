{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import libraries such as `torch`, `numpy`, `matplotlib`, and any other necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import sem  # For calculating confidence intervals\n",
    "from itertools import islice  # For slicing iterators\n",
    "from functools import partial  # For creating partial functions\n",
    "from tqdm.auto import tqdm  # For progress bars\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # For enhanced visualizations\n",
    "import plotly.express as px  # For interactive visualizations\n",
    "import transformer_lens\n",
    "import torch\n",
    "# import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer, FactoredMatrix\n",
    "# Import stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "\n",
    "from jaxtyping import Float\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "sys.path.insert(0, \"../generators\")\n",
    "sys.path.insert(0, \"generators\")\n",
    "\n",
    "\n",
    "from generators.string_reversal import StringReversalGenerator\n",
    "import transformers\n",
    "import itertools\n",
    "\n",
    "\n",
    "# Ensure plots are displayed inline in Jupyter Notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=9\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/TransformerLensOrg/TransformerLens.git@refs/pull/900/head\n",
      "  Cloning https://github.com/TransformerLensOrg/TransformerLens.git (to revision refs/pull/900/head) to /tmp/pip-req-build-41u2xcmi\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/TransformerLensOrg/TransformerLens.git /tmp/pip-req-build-41u2xcmi\n",
      "\u001b[33m  WARNING: Did not find branch or tag 'refs/pull/900/head', assuming revision or ref.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running command git fetch -q https://github.com/TransformerLensOrg/TransformerLens.git refs/pull/900/head\n",
      "  Running command git checkout -q b9e5bd8cc9390e6f3efcf0792e2b2dd023734357\n",
      "  Resolved https://github.com/TransformerLensOrg/TransformerLens.git to commit b9e5bd8cc9390e6f3efcf0792e2b2dd023734357\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: jaxtyping>=0.2.11 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from transformer-lens==0.0.0) (0.3.2)\n",
      "Requirement already satisfied: accelerate>=0.23.0 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from transformer-lens==0.0.0) (1.6.0)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from transformer-lens==0.0.0) (4.67.1)\n",
      "Requirement already satisfied: einops>=0.6.0 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from transformer-lens==0.0.0) (0.8.1)\n",
      "Requirement already satisfied: wandb>=0.13.5 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from transformer-lens==0.0.0) (0.19.6)\n",
      "Requirement already satisfied: transformers-stream-generator<0.0.6,>=0.0.5 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from transformer-lens==0.0.0) (0.0.5)\n",
      "Requirement already satisfied: datasets>=2.7.1 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from transformer-lens==0.0.0) (3.5.1)\n",
      "Requirement already satisfied: typing-extensions in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from transformer-lens==0.0.0) (4.12.2)\n",
      "Requirement already satisfied: rich>=12.6.0 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from transformer-lens==0.0.0) (14.0.0)\n",
      "Requirement already satisfied: numpy>=1.24 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from transformer-lens==0.0.0) (2.2.2)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from transformer-lens==0.0.0) (2.2.3)\n",
      "Requirement already satisfied: torch>=2.2 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from transformer-lens==0.0.0) (2.6.0)\n",
      "Requirement already satisfied: transformers>=4.43 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from transformer-lens==0.0.0) (4.50.3)\n",
      "Requirement already satisfied: typeguard<5.0,>=4.2 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from transformer-lens==0.0.0) (4.4.2)\n",
      "Requirement already satisfied: fancy-einsum>=0.0.3 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from transformer-lens==0.0.0) (0.0.3)\n",
      "Requirement already satisfied: beartype<0.15.0,>=0.14.1 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from transformer-lens==0.0.0) (0.14.1)\n",
      "Requirement already satisfied: better-abc<0.0.4,>=0.0.3 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from transformer-lens==0.0.0) (0.0.3)\n",
      "Requirement already satisfied: sentencepiece in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from transformer-lens==0.0.0) (0.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (0.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (24.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (0.5.2)\n",
      "Requirement already satisfied: pyyaml in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (6.0.2)\n",
      "Requirement already satisfied: psutil in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (6.1.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2.32.3)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (0.70.16)\n",
      "Requirement already satisfied: filelock in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.17.0)\n",
      "Requirement already satisfied: xxhash in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.5.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (20.0.0)\n",
      "Requirement already satisfied: fsspec[http]<=2025.3.0,>=2023.1.0 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2025.2.0)\n",
      "Requirement already satisfied: aiohttp in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.11.18)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (0.3.8)\n",
      "Requirement already satisfied: wadler-lindig>=0.1.3 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from jaxtyping>=0.2.11->transformer-lens==0.0.0) (0.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2025.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2025.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from rich>=12.6.0->transformer-lens==0.0.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.19.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (12.4.127)\n",
      "Requirement already satisfied: jinja2 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (3.1.5)\n",
      "Requirement already satisfied: triton==3.2.0 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (3.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (12.3.1.170)\n",
      "Requirement already satisfied: networkx in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (0.6.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (12.4.127)\n",
      "Requirement already satisfied: sympy==1.13.1 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (11.2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.2->transformer-lens==0.0.0) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from transformers>=4.43->transformer-lens==0.0.0) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from transformers>=4.43->transformer-lens==0.0.0) (0.21.0)\n",
      "Requirement already satisfied: setproctitle in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.3.4)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.1.44)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (0.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (5.29.3)\n",
      "Requirement already satisfied: platformdirs in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (4.3.6)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (2.10.6)\n",
      "Requirement already satisfied: setuptools in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (59.6.0)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (8.1.8)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (2.21.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer-lens==0.0.0) (1.17.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.6.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (0.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (6.4.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.20.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (25.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (2.6.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0) (4.0.12)\n",
      "Requirement already satisfied: mdurl~=0.1 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens==0.0.0) (0.1.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from pydantic<3,>=2.6->wandb>=0.13.5->transformer-lens==0.0.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from pydantic<3,>=2.6->wandb>=0.13.5->transformer-lens==0.0.0) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer-lens==0.0.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer-lens==0.0.0) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer-lens==0.0.0) (2025.1.31)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer-lens==0.0.0) (2.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from jinja2->torch>=2.2->transformer-lens==0.0.0) (3.0.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /mnt/silenos/silenos1/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0) (5.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/TransformerLensOrg/TransformerLens.git@refs/pull/900/head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "#checkpoint_path_old = \"checkpoints/Qwen2.5-1.5B-Instruct_string_reversal_finetuned.weights\"\n",
    "#checkpoint_path_new = \"checkpoints/Qwen2.5-1.5B-Instruct_string_reversal_finetuned_hooked.weights\"\n",
    "#model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "#checkpoint_path_old = \"checkpoints/old/llama_instruct_string_reversal_finetuned.weights\"\n",
    "#checkpoint_path_new = \"checkpoints/llama_instruct_string_reversal_finetuned_hooked.weights\"\n",
    "model_name = \"google/gemma-3-1b-it\"\n",
    "checkpoint_path_old = \"checkpoints/gemma_3_1b_it_string_reversal_finetuned.weights\"\n",
    "checkpoint_path_new = \"checkpoints/gemma_3_1b_it_string_reversal_finetuned_hooked.weights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformer_lens.pretrained.weight_conversions import convert_gemma3_weights\n",
    "from transformers import AutoConfig, AutoModelForCausalLM\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_config(config)\n",
    "model.load_state_dict(torch.load(checkpoint_path_old, weights_only=True))\n",
    "hooked_config = transformer_lens.loading.get_pretrained_model_config(model_name)\n",
    "new_state_dict = convert_gemma3_weights(model, hooked_config)\n",
    "torch.save(new_state_dict, checkpoint_path_new)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    }
   ],
   "source": [
    "config = transformer_lens.loading.get_pretrained_model_config(model_name)\n",
    "model = transformer_lens.HookedTransformer(config)\n",
    "model.load_and_process_state_dict(torch.load(checkpoint_path_new, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HookedTransformer(\n",
      "  (embed): Embed()\n",
      "  (hook_embed): HookPoint()\n",
      "  (blocks): ModuleList(\n",
      "    (0-25): 26 x TransformerBlock(\n",
      "      (ln1): RMSNorm(\n",
      "        (hook_scale): HookPoint()\n",
      "        (hook_normalized): HookPoint()\n",
      "      )\n",
      "      (ln1_post): RMSNorm(\n",
      "        (hook_scale): HookPoint()\n",
      "        (hook_normalized): HookPoint()\n",
      "      )\n",
      "      (ln2): RMSNorm(\n",
      "        (hook_scale): HookPoint()\n",
      "        (hook_normalized): HookPoint()\n",
      "      )\n",
      "      (ln2_post): RMSNorm(\n",
      "        (hook_scale): HookPoint()\n",
      "        (hook_normalized): HookPoint()\n",
      "      )\n",
      "      (attn): GroupedQueryAttention(\n",
      "        (hook_k): HookPoint()\n",
      "        (hook_q): HookPoint()\n",
      "        (hook_v): HookPoint()\n",
      "        (hook_z): HookPoint()\n",
      "        (hook_attn_scores): HookPoint()\n",
      "        (hook_pattern): HookPoint()\n",
      "        (hook_result): HookPoint()\n",
      "        (hook_rot_k): HookPoint()\n",
      "        (hook_rot_q): HookPoint()\n",
      "        (q_norm): RMSNorm(\n",
      "          (hook_scale): HookPoint()\n",
      "          (hook_normalized): HookPoint()\n",
      "        )\n",
      "        (k_norm): RMSNorm(\n",
      "          (hook_scale): HookPoint()\n",
      "          (hook_normalized): HookPoint()\n",
      "        )\n",
      "      )\n",
      "      (mlp): GatedMLP(\n",
      "        (hook_pre): HookPoint()\n",
      "        (hook_pre_linear): HookPoint()\n",
      "        (hook_post): HookPoint()\n",
      "      )\n",
      "      (hook_attn_in): HookPoint()\n",
      "      (hook_q_input): HookPoint()\n",
      "      (hook_k_input): HookPoint()\n",
      "      (hook_v_input): HookPoint()\n",
      "      (hook_mlp_in): HookPoint()\n",
      "      (hook_attn_out): HookPoint()\n",
      "      (hook_mlp_out): HookPoint()\n",
      "      (hook_ln1_q_out): HookPoint()\n",
      "      (hook_ln1_v_out): HookPoint()\n",
      "      (hook_ln1_k_out): HookPoint()\n",
      "      (hook_ln2_out): HookPoint()\n",
      "      (hook_ln1_post_out): HookPoint()\n",
      "      (hook_ln2_post_out): HookPoint()\n",
      "      (hook_resid_pre): HookPoint()\n",
      "      (hook_resid_mid): HookPoint()\n",
      "      (hook_resid_post): HookPoint()\n",
      "    )\n",
      "  )\n",
      "  (ln_final): RMSNorm(\n",
      "    (hook_scale): HookPoint()\n",
      "    (hook_normalized): HookPoint()\n",
      "  )\n",
      "  (unembed): Unembed()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Helper Functions\n",
    "Define functions for computing accuracy, confidence intervals, and visualizing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Helper Functions\n",
    "best_heads = {}\n",
    "def fix_attn_pattern_hook(\n",
    "    value: Float[torch.Tensor, \"batch pos head_index d_head\"],\n",
    "    hook: HookPoint,\n",
    "    attn_labels_1_idx,\n",
    "    heads_to_reinforce,\n",
    "    threshold\n",
    ") -> Float[torch.Tensor, \"batch pos head_index d_head\"]:\n",
    "    #value[:, :, :, :] += torch.tensor(neco, dtype=torch.float32).cuda()\n",
    "    batch, heads, seq_len, _ = value.shape \n",
    "    \n",
    "    layer = int(hook.name.split(\".\")[1])\n",
    "    if layer not in heads_to_reinforce.keys():\n",
    "        return\n",
    "    for h in range(heads):\n",
    "        if h not in heads_to_reinforce[layer]:\n",
    "            continue\n",
    "        #visualize_attention_heads(value, None, title=\"Example Attention Heatmap\", heads=[heads_to_reinforce[layer]])\n",
    "        acc = 0\n",
    "        for i in range(seq_len):\n",
    "            for j in range(seq_len):\n",
    "                if (i, j) in attn_labels_1_idx and value[0, h, i, j] >= threshold:\n",
    "                    value[0, h, i, j] += 0.6\n",
    "                    #acc += value[0, h, i, j]\n",
    "                    pass\n",
    "        #best_heads[(layer, h)] = best_heads.get((layer, h), 0) + acc\n",
    "        #print(\"After corrections\")\n",
    "        #visualize_attention_heads(value, None, title=\"Example Attention Heatmap\", heads=[heads_to_reinforce[layer]])\n",
    "\n",
    "    return value\n",
    "\n",
    "def compute_accuracy(logits, targets, ignore_index=-100):\n",
    "    \"\"\"\n",
    "    Compute accuracy by comparing predicted tokens with target tokens.\n",
    "    Ignores tokens with the specified ignore_index.\n",
    "    \"\"\"\n",
    "    predictions = torch.argmax(logits, dim=-1)  # Get predicted token indices\n",
    "    correct = (predictions == targets) & (targets != ignore_index)  # Ignore padding tokens\n",
    "    accuracy = correct.sum().item() / (targets != ignore_index).sum().item()\n",
    "    return accuracy\n",
    "\n",
    "def compute_confidence_interval(data, confidence=0.95):\n",
    "    \"\"\"\n",
    "    Compute the confidence interval for a given dataset.\n",
    "    Uses the standard error of the mean (SEM) and the t-distribution.\n",
    "    \"\"\"\n",
    "    mean = np.mean(data)\n",
    "    error = sem(data)  # Standard error of the mean\n",
    "    margin = error * 1.96  # Approximation for 95% confidence interval\n",
    "    return mean, margin\n",
    "\n",
    "def plot_accuracy_curve(lengths, accuracies, confidence_intervals, title=\"Accuracy vs Input Length\"):\n",
    "    \"\"\"\n",
    "    Plot accuracy as a function of input length with enhanced confidence intervals using Seaborn.\n",
    "    \"\"\"\n",
    "    lengths = np.array(lengths)\n",
    "    accuracies = np.array(accuracies)\n",
    "    confidence_intervals = np.array(confidence_intervals)\n",
    "\n",
    "    # Create a DataFrame for Seaborn\n",
    "    import pandas as pd\n",
    "    data = pd.DataFrame({\n",
    "        \"Input Length\": lengths,\n",
    "        \"Accuracy\": accuracies,\n",
    "        \"Lower Bound\": accuracies - confidence_intervals,\n",
    "        \"Upper Bound\": accuracies + confidence_intervals\n",
    "    })\n",
    "\n",
    "    # Plot using Seaborn\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.lineplot(data=data, x=\"Input Length\", y=\"Accuracy\", marker=\"o\", label=\"Accuracy\")\n",
    "    plt.fill_between(\n",
    "        data[\"Input Length\"],\n",
    "        data[\"Lower Bound\"],\n",
    "        data[\"Upper Bound\"],\n",
    "        color=\"blue\",\n",
    "        alpha=0.2,\n",
    "        label=\"Confidence Interval\"\n",
    "    )\n",
    "    plt.xlabel(\"Input Length\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data Samples\n",
    "Generate random data samples of varying lengths using the data generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Samples: 100%|██████████| 18/18 [00:06<00:00,  2.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate Data Samples\n",
    "\n",
    "# Initialize the data generator with the model's tokenizer\n",
    "data_generator = StringReversalGenerator(\n",
    "    tokenizer=model.tokenizer,\n",
    "    seed=0,\n",
    "    use_few_shot=True,\n",
    "    use_instruction=True,\n",
    "    apply_chat_template=True,\n",
    ")\n",
    "\n",
    "# Function to generate random samples of varying lengths\n",
    "def generate_samples_for_lengths(lengths, num_samples=10):\n",
    "    \"\"\"\n",
    "    Generate random data samples for a list of input lengths.\n",
    "\n",
    "    Parameters:\n",
    "        lengths (list): List of input lengths to generate samples for.\n",
    "        num_samples (int): Number of samples to generate for each length.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are lengths and values are lists of samples.\n",
    "    \"\"\"\n",
    "    samples_by_length = {}\n",
    "    for length in tqdm(lengths, desc=\"Generating Samples\"):\n",
    "        data_generator.length = (length, length)  # Set the length range\n",
    "        samples = list(islice(data_generator.generate_samples(), num_samples))\n",
    "        samples_by_length[length] = samples\n",
    "    return samples_by_length\n",
    "\n",
    "# Define the input lengths and number of samples per length\n",
    "input_lengths = [10, 20, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800]\n",
    "#input_lengths = [100, 800]\n",
    "num_samples_per_length = 10\n",
    "\n",
    "# Generate the data samples\n",
    "samples_by_length = generate_samples_for_lengths(input_lengths, num_samples_per_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure Accuracy Across Input Lengths\n",
    "Iterate over different input lengths, compute accuracy for a statistically significant number of samples, and store the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:   0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622139/1726364805.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(input_ids).unsqueeze(0).to(device)  # Add batch dimension\n",
      "/tmp/ipykernel_622139/1726364805.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target_ids = torch.tensor(target_ids).unsqueeze(0).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring Accuracy:   0%|          | 0/18 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Run the model and compute accuracy\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 36\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_with_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogits\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mfwd_hooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;66;43;03m#(is_attn_scores, partial(fix_attn_pattern_hook, attn_labels_1_idx=attn_labels_1_idx, heads_to_reinforce=dict(heads_to_reinforce), threshold=threshold))\u001b[39;49;00m\n\u001b[1;32m     39\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m compute_accuracy(logits, target_ids)\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(accuracy)\n",
      "File \u001b[0;32m/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages/transformer_lens/hook_points.py:456\u001b[0m, in \u001b[0;36mHookedRootModule.run_with_hooks\u001b[0;34m(self, fwd_hooks, bwd_hooks, reset_hooks_end, clear_contexts, *model_args, **model_kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    452\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWARNING: Hooks will be reset at the end of run_with_hooks. This removes the backward hooks before a backward pass can occur.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    453\u001b[0m     )\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhooks(fwd_hooks, bwd_hooks, reset_hooks_end, clear_contexts) \u001b[38;5;28;01mas\u001b[39;00m hooked_model:\n\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhooked_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages/transformer_lens/HookedTransformer.py:602\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    600\u001b[0m     stop_at_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks)\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_at_layer, stop_at_layer):\n\u001b[0;32m--> 602\u001b[0m     residual \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;66;03m# Get logits and normalize\u001b[39;00m\n\u001b[1;32m    610\u001b[0m residual \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_final(residual)\n",
      "File \u001b[0;32m/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages/transformer_lens/components/transformer_block.py:249\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[0m\n\u001b[1;32m    245\u001b[0m resid_mid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_resid_mid(resid_pre \u001b[38;5;241m+\u001b[39m attn_out)  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    246\u001b[0m mlp_in \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    247\u001b[0m     resid_mid \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39muse_hook_mlp_in \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_mlp_in(resid_mid\u001b[38;5;241m.\u001b[39mclone())\n\u001b[1;32m    248\u001b[0m )\n\u001b[0;32m--> 249\u001b[0m normalized_resid_mid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_ln2_out(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlp_in\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    250\u001b[0m mlp_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_mlp(normalized_resid_mid)\n\u001b[1;32m    251\u001b[0m resid_post \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_resid_post(resid_mid \u001b[38;5;241m+\u001b[39m mlp_out)  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n",
      "File \u001b[0;32m/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages/transformer_lens/components/rms_norm.py:42\u001b[0m, in \u001b[0;36mRMSNorm.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     40\u001b[0m variance \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     41\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mrsqrt(variance \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps)\n\u001b[0;32m---> 42\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhook_normalized\u001b[49m(x)\n\u001b[1;32m     43\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[1;32m     44\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_scale(x)\n",
      "File \u001b[0;32m/nlp/projekty/aver/xspiege1/algorithmic_reasoning/.env/lib/python3.10/site-packages/torch/nn/modules/module.py:1915\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1912\u001b[0m \u001b[38;5;66;03m# It is crucial that the return type is not annotated as `Any`, otherwise type checking\u001b[39;00m\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;66;03m# on `torch.nn.Module` and all its subclasses is largely disabled as a result. See:\u001b[39;00m\n\u001b[1;32m   1914\u001b[0m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/pull/115074\u001b[39;00m\n\u001b[0;32m-> 1915\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1916\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1917\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Measure Accuracy Across Input Lengths\n",
    "best_heads = {}\n",
    "# Initialize lists to store results\n",
    "lengths = []\n",
    "accuracies = []\n",
    "confidence_intervals = []\n",
    "device = \"cuda\"\n",
    "model.to(device)\n",
    "is_attn_scores = lambda name: name.endswith(\"hook_pattern\")\n",
    "\n",
    "heads_to_reinforce=[\n",
    "    (22, [7]),\n",
    "    (24, [10]),\n",
    "    (23, [0, 8, 3]),\n",
    "    (27, [8, 11, 6]),\n",
    "    (26, [1])\n",
    "\n",
    "]\n",
    "\n",
    "# Iterate over each input length\n",
    "for length, samples in tqdm(samples_by_length.items(), desc=\"Measuring Accuracy\"):\n",
    "    length_accuracies = []  # Store accuracies for the current length\n",
    "    threshold = 0\n",
    "    # Iterate over the samples for the current length\n",
    "    for sample in samples:\n",
    "        input_ids, target_ids, attn_labels = sample[1], sample[2], sample[3]  # Extract input and target IDs\n",
    "        input_ids = torch.tensor(input_ids).unsqueeze(0).to(device)  # Add batch dimension\n",
    "        target_ids = torch.tensor(target_ids).unsqueeze(0).to(device)\n",
    "        attn_labels_1_idx = set()\n",
    "        for i in range(len(attn_labels)):\n",
    "            for j in range(len(attn_labels[0])):\n",
    "                if attn_labels[i][j] == 1:\n",
    "                    attn_labels_1_idx.add((i, j))\n",
    "        # Run the model and compute accuracy\n",
    "        with torch.no_grad():\n",
    "            logits = model.run_with_hooks(input_ids, return_type=\"logits\",\n",
    "                                            fwd_hooks=[\n",
    "                                                #(is_attn_scores, partial(fix_attn_pattern_hook, attn_labels_1_idx=attn_labels_1_idx, heads_to_reinforce=dict(heads_to_reinforce), threshold=threshold))\n",
    "                                            ])\n",
    "            \n",
    "            accuracy = compute_accuracy(logits, target_ids)\n",
    "            print(accuracy)\n",
    "            length_accuracies.append(accuracy)\n",
    "\n",
    "    # Compute mean accuracy and confidence interval for the current length\n",
    "    mean_accuracy, confidence_margin = compute_confidence_interval(length_accuracies)\n",
    "    lengths.append(input_ids.shape[1])\n",
    "    accuracies.append(mean_accuracy)\n",
    "    confidence_intervals.append(confidence_margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in sorted(best_heads.items(), key=lambda item: item[1], reverse=True):\n",
    "    print(item[0][0], item[0][1], item[1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_heads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Accuracy with Confidence Intervals\n",
    "Plot the accuracy curve with confidence intervals using `matplotlib` or `plotly`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the accuracy curve with confidence intervals\n",
    "plot_accuracy_curve(\n",
    "    lengths=lengths,\n",
    "    accuracies=accuracies,\n",
    "    confidence_intervals=confidence_intervals,\n",
    "    title=\"Accuracy vs Input Length with Confidence Intervals\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create a DataFrame for Plotly\n",
    "data = pd.DataFrame({\n",
    "    \"Input Length\": lengths,\n",
    "    \"Accuracy\": accuracies,\n",
    "    \"Lower Bound\": np.array(accuracies) - np.array(confidence_intervals),\n",
    "    \"Upper Bound\": np.array(accuracies) + np.array(confidence_intervals)\n",
    "})\n",
    "\n",
    "# Create the main accuracy line\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=data[\"Input Length\"],\n",
    "    y=data[\"Accuracy\"],\n",
    "    mode=\"lines+markers\",\n",
    "    name=\"Accuracy\",\n",
    "    line=dict(color=\"blue\"),\n",
    "    marker=dict(size=8)\n",
    "))\n",
    "\n",
    "# Add the confidence interval as a shaded area\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=np.concatenate([data[\"Input Length\"], data[\"Input Length\"][::-1]]),\n",
    "    y=np.concatenate([data[\"Upper Bound\"], data[\"Lower Bound\"][::-1]]),\n",
    "    fill=\"toself\",\n",
    "    fillcolor=\"rgba(0, 0, 255, 0.2)\",  # Light blue fill\n",
    "    line=dict(color=\"rgba(255,255,255,0)\"),  # No border line\n",
    "    hoverinfo=\"skip\",\n",
    "    name=\"Confidence Interval\"\n",
    "))\n",
    "\n",
    "# Update layout for better visualization\n",
    "fig.update_layout(\n",
    "    title=\"Accuracy vs Input Length with Confidence Intervals\",\n",
    "    xaxis_title=\"Input Length\",\n",
    "    yaxis_title=\"Accuracy\",\n",
    "    template=\"plotly_white\",\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qwen_vanilla_data = data\n",
    "#vanilla_data = data3\n",
    "#extrapolate_data = data2\n",
    "#vanilla_data.to_csv(\"string_reversal_vanilla_extrapolate.csv\")\n",
    "#extrapolate_data.to_csv(\"string_reversal_fix_extrapolate.csv\")\n",
    "#qwen_vanilla_data.to_csv(\"qwen_string_reversal_vanilla_extrapolate.csv\")\n",
    "qwen_reinforced_data = data\n",
    "qwen_reinforced_data.to_csv(\"qwen_string_reversal_reinforced_extrapolate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Load the CSV files\n",
    "string_reversal_vanilla = pd.read_csv(\"llama_string_reversal_vanilla_extrapolate.csv\")\n",
    "string_reversal_reinforced = pd.read_csv(\"llama_string_reversal_reinforcement_extrapolate.csv\")\n",
    "value_assignment_vanilla = pd.read_csv(\"llama_value_assignment_vanilla_extrapolate.csv\")\n",
    "value_assignment_reinforced = pd.read_csv(\"llama_value_assign_reinforcement_extrapolate.csv\")\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add the string reversal vanilla model (LLama3-SFT) accuracy curve\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=string_reversal_vanilla[\"Input Length\"],\n",
    "    y=string_reversal_vanilla[\"Accuracy\"],\n",
    "    mode=\"lines+markers\",\n",
    "    name=\"String Reversal - Llama-3.2-1B-Instruct - Vanilla\",\n",
    "    line=dict(color=\"blue\", width=2),\n",
    "    marker=dict(size=6)\n",
    "))\n",
    "\n",
    "# Add the confidence interval for the string reversal vanilla model\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=np.concatenate([string_reversal_vanilla[\"Input Length\"], string_reversal_vanilla[\"Input Length\"][::-1]]),\n",
    "    y=np.concatenate([string_reversal_vanilla[\"Upper Bound\"], string_reversal_vanilla[\"Lower Bound\"][::-1]]),\n",
    "    fill=\"toself\",\n",
    "    fillcolor=\"rgba(0, 0, 255, 0.2)\",  # Light blue fill\n",
    "    line=dict(color=\"rgba(255,255,255,0)\"),\n",
    "    hoverinfo=\"skip\",\n",
    "    name=\"String Reversal - Llama-3.2-1B-Instruct - Vanilla - Confidence Interval\"\n",
    "))\n",
    "\n",
    "# Add the string reversal reinforced model (LLama3-SFT-AttentionReinforcement) accuracy curve\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=string_reversal_reinforced[\"Input Length\"],\n",
    "    y=string_reversal_reinforced[\"Accuracy\"],\n",
    "    mode=\"lines+markers\",\n",
    "    name=\"String Reversal - Llama-3.2-1B-Instruct - AttentionReinforcement (Ours)\",\n",
    "    line=dict(color=\"green\", width=2),\n",
    "    marker=dict(size=6)\n",
    "))\n",
    "\n",
    "# Add the confidence interval for the string reversal reinforced model\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=np.concatenate([string_reversal_reinforced[\"Input Length\"], string_reversal_reinforced[\"Input Length\"][::-1]]),\n",
    "    y=np.concatenate([string_reversal_reinforced[\"Upper Bound\"], string_reversal_reinforced[\"Lower Bound\"][::-1]]),\n",
    "    fill=\"toself\",\n",
    "    fillcolor=\"rgba(0, 255, 0, 0.2)\",  # Light green fill\n",
    "    line=dict(color=\"rgba(255,255,255,0)\"),\n",
    "    hoverinfo=\"skip\",\n",
    "    name=\"String Reversal - Llama-3.2-1B-Instruct - AttentionReinforcement (Ours) - Confidence Interval\"\n",
    "))\n",
    "\n",
    "# Add the value assignment vanilla model (LLama3-SFT) accuracy curve\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=value_assignment_vanilla[\"Input Length\"],\n",
    "    y=value_assignment_vanilla[\"Accuracy\"],\n",
    "    mode=\"lines+markers\",\n",
    "    name=\"Value Assignment - Llama-3.2-1B-Instruct - Vanilla\",\n",
    "    line=dict(color=\"red\", width=2),\n",
    "    marker=dict(size=6)\n",
    "))\n",
    "\n",
    "# Add the confidence interval for the value assignment vanilla model\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=np.concatenate([value_assignment_vanilla[\"Input Length\"], value_assignment_vanilla[\"Input Length\"][::-1]]),\n",
    "    y=np.concatenate([value_assignment_vanilla[\"Upper Bound\"], value_assignment_vanilla[\"Lower Bound\"][::-1]]),\n",
    "    fill=\"toself\",\n",
    "    fillcolor=\"rgba(255, 0, 0, 0.2)\",  # Light red fill\n",
    "    line=dict(color=\"rgba(255,255,255,0)\"),\n",
    "    hoverinfo=\"skip\",\n",
    "    name=\"Value Assignment - Llama-3.2-1B-Instruct - Vanilla - Confidence Interval\"\n",
    "))\n",
    "\n",
    "# Add the value assignment reinforced model (LLama3-SFT-AttentionReinforcement) accuracy curve\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=value_assignment_reinforced[\"Input Length\"],\n",
    "    y=value_assignment_reinforced[\"Accuracy\"],\n",
    "    mode=\"lines+markers\",\n",
    "    name=\"Value Assignment - Llama-3.2-1B-Instruct - AttentionReinforcement (Ours)\",\n",
    "    line=dict(color=\"purple\", width=2),\n",
    "    marker=dict(size=6)\n",
    "))\n",
    "\n",
    "# Add the confidence interval for the value assignment reinforced model\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=np.concatenate([value_assignment_reinforced[\"Input Length\"], value_assignment_reinforced[\"Input Length\"][::-1]]),\n",
    "    y=np.concatenate([value_assignment_reinforced[\"Upper Bound\"], value_assignment_reinforced[\"Lower Bound\"][::-1]]),\n",
    "    fill=\"toself\",\n",
    "    fillcolor=\"rgba(128, 0, 128, 0.2)\",  # Light purple fill\n",
    "    line=dict(color=\"rgba(255,255,255,0)\"),\n",
    "    hoverinfo=\"skip\",\n",
    "    name=\"Value Assignment - Llama-3.2-1B-Instruct - AttentionReinforcement (Ours) - Confidence Interval\"\n",
    "))\n",
    "\n",
    "# Update layout for better visualization\n",
    "fig.update_layout(\n",
    "    title=\"Accuracy vs Input Length for String Reversal and Value Assignment Tasks\",\n",
    "    xaxis_title=\"Input Length (tokens)\",\n",
    "    yaxis_title=\"Accuracy\",\n",
    "    template=\"plotly_white\",\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
